{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f225bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Copyright (C) 2021 by Sonja Filiposka <sonja.filiposka@finki.ukim.mk>\n",
    "#\n",
    "# This code is licensed under a Creative Commons Attribution 4.0 International License. (see LICENSE.txt for details)\n",
    "#\n",
    "# General Description - this notebook is used to extract the delay and the handover information from OMNET output vector file\n",
    "# It creates two types of output files: \n",
    "#    - mobile network communication delay as reported by OMNET\n",
    "#      - a csv file with the delay for each communication exchange\n",
    "#    - initial positioning and migration files that are used as input for CloudSim \n",
    "#       - initial positioning file defines the start and end time for each car/service and the initial community \n",
    "#         based on location of tha car and the location of the base stations (see comments in code)\n",
    "#       - migration file defines the time stamp when a car moves from one community to another based on relative location to the nearest base station\n",
    "#\n",
    "\n",
    "\n",
    "def delay(vector, output):\n",
    "\n",
    "    # parameters\n",
    "    # 1 = $vector - input.file name\n",
    "    # 2 = $output - output.file name\n",
    "\n",
    "    \n",
    "    # First prepare the output file from OMNET, vector-0.vec\n",
    "    # new output file: table.txt\n",
    "\n",
    "    # add only the lines that start with a number\n",
    "    !grep \"^[0-9]\" $vector > table.txt\n",
    "    \n",
    "    #import vaex as vx\n",
    "    #import numpy as np\n",
    "\n",
    "    data = vx.read_csv(\"table.txt\", sep='\\t', header=None,\n",
    "            names=[\"vector\", \"event\", \"time\", \"delay\"], \n",
    "            usecols=[\"vector\",\"time\",\"delay\"],\n",
    "            convert=True,\n",
    "            chunk_size=150_000_000)\n",
    "\n",
    "    #clean up\n",
    "    !rm table.txt\n",
    "\n",
    "    # also need another file with vector -> car mapping\n",
    "\n",
    "    !grep \"].lteNic.rlc.um rlcDelayDl:vector\" $vector > cars.vec\n",
    "\n",
    "    !grep -Eo '[0-9]+([^0-9]+[0-9]+)' cars.vec > cars.v\n",
    "    !sed -e \"s/NRSeveralBSALC.car\\[//g\" < cars.v > cars.txt\n",
    "\n",
    "    #clean up\n",
    "    !rm cars.v*\n",
    "\n",
    "    # this produces a two column file with vector car mapping information, to be used as dictionary\n",
    "\n",
    "    #build the dictionary\n",
    "    d = {}\n",
    "    with open(\"cars.txt\") as f:\n",
    "        for line in f:\n",
    "            (key, val) = line.split()\n",
    "            d[int(key)] = int(val)\n",
    "\n",
    "    #clean up\n",
    "    !rm cars.txt\n",
    "\n",
    "    # make the car vector mapping, if no entry in dictionary -1 will be put\n",
    "    data['car'] = data['vector'].map(d, default_value = -1 )\n",
    "\n",
    "    # need to drop vectors that are not in dictionary\n",
    "    filtered = data[data['car']!=-1]\n",
    "\n",
    "    #drop the vector column we don't need it any more\n",
    "    filtered = filtered.drop('vector')\n",
    "\n",
    "    # save to output file\n",
    "    df = filtered.to_pandas_df()\n",
    "    cols = ['car','time','delay']\n",
    "    df = df[cols]\n",
    "    df.to_csv(output, index=False)\n",
    "    \n",
    "    # now to handover\n",
    "\n",
    "    # goal: to extract the handover information from the omnet output file and use it to create the input files for cloudsim\n",
    "\n",
    "    # it is in a statistic named \"servingCell\" that can be collected in a vector fashion\n",
    "\n",
    "    !grep servingCell:vector $vector > cell.txt\n",
    "    \n",
    "    # cell.txt contains rows in format vector XXX NRSeveralBSALC.car[YYY].lteNic.phy servingCell:vector ETV    \n",
    "    # extract the numbers\n",
    "    !grep -Eo '[0-9]+([^0-9]+[0-9]+)' cell.txt > cell.v\n",
    "    !sed -e \"s/NRSeveralBSALC.car\\[//g\" < cell.v > cell.txt\n",
    "\n",
    "    #clean up\n",
    "    !rm cell.v*\n",
    "\n",
    "    # this produces a two column file with vector car mapping information, to be used as dictionary\n",
    "    \n",
    "    # build the handover dictionary\n",
    "    hd = {}\n",
    "    with open(\"cell.txt\") as f:\n",
    "        for line in f:\n",
    "            (key, val) = line.split()\n",
    "            hd[int(key)] = int(val)\n",
    "        \n",
    "    #clean up\n",
    "    !rm cell.txt\n",
    "\n",
    "    # make the car vector mapping, if no entry in dictionary -1 will be put\n",
    "    data['car'] = data['vector'].map(hd, default_value = -1 )\n",
    "\n",
    "    # need to drop vectors that are not in dictionary\n",
    "    handovers = data[data['car']!=-1]\n",
    "    # save memory\n",
    "    del data\n",
    "    !rm table.txt.hdf5\n",
    "\n",
    "    #drop the vector column we don't need it any more\n",
    "    handovers = handovers.drop('vector')\n",
    "\n",
    "    #rename delay column to cell column\n",
    "    handovers.rename('delay', 'cell')\n",
    "\n",
    "    # base stations - communities mapping \n",
    "    # B1: Luceros - 0\n",
    "    # B2: Gabriel Miró - 1\n",
    "    # B3: Teatro Arniches - 2\n",
    "    # B4: Plaza del Mercado - 3\n",
    "    # B5: Paseo Canalejas - 4\n",
    "    # B6: Parque de La Ereta - 5\n",
    "    # B7: Castillo Santa Bárbara - 6\n",
    "    # B8: Playa Postiguet - 7\n",
    "    # B9: Zona Volvo - 8\n",
    "\n",
    "    # 2 input files for CloudSim\n",
    "\n",
    "    # initialPositioning.txt\n",
    "    # example\n",
    "    # # simulation time\t nodes\t communities\n",
    "    # 9999 8692 9\n",
    "    # # VM-CSid\t start_time\t end_time\t com_id\n",
    "    # 1-0\t1.00\t36\t1\n",
    "\n",
    "    # VM == car\n",
    "\n",
    "    # initialPositioning\n",
    "    # for each car get first base station, first time stamp in handovers, last time stamp from dfH dataset\n",
    "    min_df = handovers\n",
    "    min_dfg = min_df.groupby(\"car\").agg({'time': 'min'})\n",
    "    min_df = min_df.join(min_dfg, on='car', rsuffix='_min')\n",
    "    min_df = min_df[min_df['time'] == min_df['time_min']].drop(['time_min', 'car_min'])\n",
    "    min_df = min_df.sort(by=['car'])\n",
    "    del min_dfg\n",
    "    \n",
    "    # for max time must search the previous data frame with the delay logs and find the last occurences\n",
    "    max_df = filtered\n",
    "    max_dfg = filtered.groupby(\"car\").agg({'time': 'max'})\n",
    "    \n",
    "    # save memory\n",
    "    del filtered \n",
    "\n",
    "    \n",
    "    max_df = max_df.join(max_dfg, on='car', rsuffix='_max')\n",
    "    max_df = max_df[max_df['time'] == max_df['time_max']].drop(['time_max', 'car_max'])\n",
    "    del max_dfg\n",
    "\n",
    "    # turns out that there might be duplicates in the dataset (two packets received with the same max timestamp)\n",
    "    # need to drop duplicate rows for cars\n",
    "    # drop_duplicates works only for pandas df\n",
    "    dfmax = max_df.to_pandas_df()\n",
    "    dfmax = dfmax.drop_duplicates(subset=['car'])\n",
    "    max_df = vx.from_pandas(dfmax)\n",
    "    del dfmax\n",
    "\n",
    "    max_df = max_df.sort(by=['car'])\n",
    "    max_df.rename('time', 'end_time')\n",
    "    max_df.rename('delay', 'end_delay')\n",
    "    max_df.rename('car', 'end_car')\n",
    "\n",
    "    #combine the two data sets\n",
    "    # car start end cell\n",
    "\n",
    "    initialPos = min_df.join(max_df, left_on='car', right_on='end_car')\n",
    "    # save memory\n",
    "    del max_df\n",
    "    \n",
    "    # there might be no delay vectors for a given car, in that case set end_time to maxTime\n",
    "    initialPos = initialPos.fillna(value=maxTime, column_names=['end_time'])\n",
    "\n",
    "    # drop\n",
    "    initialPos = initialPos.drop('end_delay')\n",
    "    initialPos = initialPos.drop('end_car')\n",
    "\n",
    "    # community = BS - 1   #CS = car + 1\n",
    "    initialPos['cell'] = initialPos.cell - 1\n",
    "    initialPos['cell'] = initialPos.cell.astype('int')\n",
    "    initialPos['car'] = initialPos.car + 1\n",
    "    initialPos['car'] = initialPos.car.astype('str')\n",
    "    initialPos['car'] = initialPos.car + '-0'\n",
    "\n",
    "    initialPos.rename('car', 'VM-CSid')\n",
    "    initialPos.rename('time', 'start_time')\n",
    "    initialPos.rename('cell', 'com_id')\n",
    "\n",
    "\n",
    "    # create initialPositioning file\n",
    "    # save to output file\n",
    "    dfIP = initialPos.to_pandas_df()\n",
    "    #save memory \n",
    "    del initialPos\n",
    "\n",
    "    # before printing to file check for concurrent events\n",
    "    # cloudsim can not work if there are two inits at the same time\n",
    "    # if such a thing occurs add +0.01 to the other event\n",
    "\n",
    "    dupl = dfIP.groupby('start_time').cumcount()\n",
    "#    print(dupl[dupl>0])\n",
    "    dfIP['start_time'] = dfIP['start_time'].where(dupl.eq(0), dfIP['start_time'] + dupl*0.01)\n",
    "    del dupl\n",
    "    \n",
    "    cols = ['VM_CSid','start_time','end_time','com_id']\n",
    "    dfIP = dfIP[cols]\n",
    "    dfIP.to_csv('IP.txt', index=False, sep='\\t')\n",
    "\n",
    "    # add two rows in the begining to conform to format\n",
    "    # # simulation time\t nodes\t communities\n",
    "    # 9999 8692 9\n",
    "\n",
    "    IPFile = \"initialPositioning-\" + str(i) + '.txt'\n",
    "\n",
    "    !echo \"# simulation time\tnodes\tcommunities\" > $IPFile\n",
    "    maxCars = dfIP.__len__()\n",
    "    !echo \"$maxTime $maxCars $communities\" >> $IPFile\n",
    "\n",
    "    ! cat IP.txt >> $IPFile\n",
    "\n",
    "    #cleanup\n",
    "    !rm IP.txt\n",
    "    del dfIP\n",
    "    \n",
    "    # migrations file\n",
    "\n",
    "    # migrations.txt\n",
    "    # example\n",
    "    # # simulation time\t nodes\t communities\n",
    "    # 9999 8692 9\n",
    "    # # time stamp\t node id\t community id\n",
    "    # 20\t3-0\t0\n",
    "\n",
    "    # need to work with handovers data set but drop the first occurence because it is in initialPoisitioning\n",
    "    migrations = pd.concat([handovers.to_pandas_df(), min_df.to_pandas_df(), min_df.to_pandas_df()]).drop_duplicates(keep=False)\n",
    "\n",
    "    # save memory \n",
    "    del handovers\n",
    "    del min_df\n",
    "    \n",
    "    # sort migrations by time\n",
    "    migrations = migrations.sort_values(by=['time'])\n",
    "\n",
    "    # create migrations file\n",
    "    # save to output file\n",
    "    migrations['car'] = migrations.car + 1\n",
    "    migrations['car'] = migrations.car.astype('str')\n",
    "    migrations['car'] = migrations.car + '-0'\n",
    "    migrations['cell'] = migrations.cell - 1\n",
    "    migrations['cell'] = migrations.cell.astype('int')\n",
    "    migrations.rename(columns = {'cell': 'com_id'}, inplace = True)\n",
    "    migrations.rename(columns = {'car': 'node_id'}, inplace = True)\n",
    "    cols = ['time','node_id','com_id']\n",
    "    migrations = migrations[cols]\n",
    "    migrations.to_csv('M.txt', index=False, sep='\\t')\n",
    "\n",
    "    # add two rows in the begining to conform to format\n",
    "    # # simulation time\t nodes\t communities\n",
    "    # 9999 8692 9\n",
    "\n",
    "    MFile = \"migrations-\" + str(i) + '.txt'\n",
    "\n",
    "    !echo \"# simulation time\tnodes\tcommunities\" > $MFile\n",
    "    !echo \"$maxTime $maxCars $communities\" >> $MFile\n",
    "\n",
    "    ! cat M.txt >> $MFile\n",
    "\n",
    "    #cleanup\n",
    "    !rm M.txt    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "537a1dca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data-disk/OMNET_logs/VideoDL-Urban-6910/vector-0.vec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MainThread:numexpr.utils:Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:MainThread:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           car      time     delay\n",
      "0            0     6.147  0.001297\n",
      "1            0     6.414  0.001269\n",
      "2            0     6.821  0.001305\n",
      "3            0     7.181  0.003149\n",
      "4            0     7.415  0.003079\n",
      "...        ...       ...       ...\n",
      "30073185  6037  9999.961  0.001462\n",
      "30073186  6037  9999.971  0.001235\n",
      "30073187  6037  9999.982  0.001970\n",
      "30073188  6037  9999.992  0.001960\n",
      "30073189  6038  9999.852  0.001619\n",
      "\n",
      "[30073190 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# measuring execution time\n",
    "%load_ext autotime\n",
    "\n",
    "# extract the delay and the handover information from omnet output vector file\n",
    "maxTime = 9999\n",
    "communities = 9\n",
    "\n",
    "#parametrised calls of notebook\n",
    "\n",
    "# VideoDL-Urban-4949; VideoDL-Urban-4951; VideoDL-Urban-4955; \n",
    "# VideoDL-Urban-5712; VideoDL-Urban-5734; \n",
    "# VideoDL-Urban-6900; VideoDL-Urban-6908; VideoDL-Urban-6923;\n",
    "# VideoDL-Urban-8589; VideoDL-Urban-8595; VideoDL-Urban-8630\n",
    "\n",
    "import numpy as np\n",
    "import vaex as vx\n",
    "import pandas as pd\n",
    "\n",
    "#text=\"/home/ubuntu/omnetpp-5.6.2/samples/UrbanALC/VideoDL-Urban-\"\n",
    "text=\"/mnt/data-disk/OMNET_logs/VideoDL-Urban-\"\n",
    "# cars = np.array([4928, 4951, 4955, 5712, 5734, 5749, 6900, 6908, 6923, 8589, 8595, 8630])\n",
    "cars = np.array([6910])\n",
    "outFile = \".csv\"\n",
    "# initialPositioning-xxxx.txt and migrations-xxxx.txt will also be created\n",
    "\n",
    "for i in cars:\n",
    "    path = text + str(i)\n",
    "    vector = path + \"/vector-0.vec\"\n",
    "    output = str(i) + outFile\n",
    "    print(vector)\n",
    "    df = delay(vector, output)\n",
    "    #check\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4bb37b-9b86-4cbd-a419-2ef18aa2895e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
